{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4849f3-51e1-4299-9f55-9c70c1f1c431",
   "metadata": {},
   "source": [
    "# Fine Tuning Models - Using Custom Data\n",
    "> Fine-tuning using your own data\n",
    "\n",
    "In this notebook, we'll use:https://huggingface.co/transformers/custom_datasets.html as a guide for our work.  The notebook headers mirror the ones of notebook 3.  However, in this notebook, we'll use our own custom data available through our `workshop-files` subdirectory.  Some code has already been provided from Notebook 2.  Other code, we will write together.  See the solutions notebook if you fall behind!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e35b6-6e7f-4a59-8ed5-9bb9ebbb8e43",
   "metadata": {},
   "source": [
    "# 0. Preliminaries\n",
    "You can use the following code to mount your drive and cd into the relevant directory.  Uncomment the git clone command if you don't have the `deep-learning-intensive` repo already cloned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ae6a5-1b4f-43de-b950-89ddf24269f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29480a8e-de29-4a9c-b700-4ed4b48c5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive\n",
    "#!git clone https://github.com/vanderbilt-data-science/deep-learning-intensive.git\n",
    "%cd deep-learning-intensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abbc1b7-f4b4-4cdd-93ed-ce92742fe4c6",
   "metadata": {},
   "source": [
    "# 1.  Installing Required Packages\n",
    "Note that this is mostly required if you're on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067752c-e281-4ffe-9140-828d158751a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers\n",
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4f46c-e1c0-4abc-9498-a45211bcf9a6",
   "metadata": {},
   "source": [
    "# 2. Importing Packages for Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa3949-c286-4a82-af4f-c5f7594a6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a371ec-98f5-4be7-b085-a2eed2f9c3d3",
   "metadata": {},
   "source": [
    "# 3. Formulate Data into Dataset\n",
    "## Read in data and convert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b6693-573c-4515-b3bc-0a70c43945c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_journalism</th>\n",
       "      <th>college major</th>\n",
       "      <th>article_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>west</td>\n",
       "      <td>enrique</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>humanities</td>\n",
       "      <td>551293</td>\n",
       "      <td>551293.txt</td>\n",
       "      <td>The rain and wind abruptly stopped, but the sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>braun</td>\n",
       "      <td>damien</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>humanities</td>\n",
       "      <td>373587</td>\n",
       "      <td>373587.txt</td>\n",
       "      <td>She patiently waited for his number to be call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osborn</td>\n",
       "      <td>ellie</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>engineering</td>\n",
       "      <td>597061</td>\n",
       "      <td>597061.txt</td>\n",
       "      <td>The chair sat in the corner where it had been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vega</td>\n",
       "      <td>cierra</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "      <td>science</td>\n",
       "      <td>434648</td>\n",
       "      <td>434648.txt</td>\n",
       "      <td>The computer wouldn't start. She banged on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cantrell</td>\n",
       "      <td>alden</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>science</td>\n",
       "      <td>532970</td>\n",
       "      <td>532970.txt</td>\n",
       "      <td>Do you really listen when you are talking with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  last_name first_name  age  years_of_journalism college major  article_id  \\\n",
       "0      west    enrique   56                   12    humanities      551293   \n",
       "1     braun     damien   43                   13    humanities      373587   \n",
       "2    osborn      ellie   22                    2   engineering      597061   \n",
       "3      vega     cierra   67                   34       science      434648   \n",
       "4  cantrell      alden   53                   23       science      532970   \n",
       "\n",
       "     filename                                               text  \n",
       "0  551293.txt  The rain and wind abruptly stopped, but the sk...  \n",
       "1  373587.txt  She patiently waited for his number to be call...  \n",
       "2  597061.txt  The chair sat in the corner where it had been ...  \n",
       "3  434648.txt  The computer wouldn't start. She banged on the...  \n",
       "4  532970.txt  Do you really listen when you are talking with...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get filenames list\n",
    "filenames = glob.glob('workshop-files/*.txt')\n",
    "\n",
    "#read file contents\n",
    "file_contents = []\n",
    "for file in filenames:\n",
    "    with open(file, 'r') as f:\n",
    "        file_contents.append(f.read())\n",
    "\n",
    "#convert to df\n",
    "tinfo_df = pd.DataFrame({'filename':[fname.split('\\\\')[-1] for fname in filenames], 'text':file_contents})\n",
    "tinfo_df['article_id'] = tinfo_df['filename'].apply(lambda x: int(x.split('.')[0]))\n",
    "\n",
    "#read author csv\n",
    "author_df = pd.read_csv('workshop-files/author_data.csv')\n",
    "\n",
    "#join\n",
    "full_df = pd.merge(author_df, tinfo_df, on='article_id')\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a908fd-e893-48cd-9753-d6d3f4b8d6c5",
   "metadata": {},
   "source": [
    "## Add training labels and split column\n",
    "Note that our data currently doesn't have any training labels, so I'll make some up here add concatenate them to the dataframe.  I'll also add a split column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651cce0-60eb-44b8-9ef0-835c27c09196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_journalism</th>\n",
       "      <th>college major</th>\n",
       "      <th>article_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>west</td>\n",
       "      <td>enrique</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>humanities</td>\n",
       "      <td>551293</td>\n",
       "      <td>551293.txt</td>\n",
       "      <td>The rain and wind abruptly stopped, but the sk...</td>\n",
       "      <td>people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>braun</td>\n",
       "      <td>damien</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>humanities</td>\n",
       "      <td>373587</td>\n",
       "      <td>373587.txt</td>\n",
       "      <td>She patiently waited for his number to be call...</td>\n",
       "      <td>people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osborn</td>\n",
       "      <td>ellie</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>engineering</td>\n",
       "      <td>597061</td>\n",
       "      <td>597061.txt</td>\n",
       "      <td>The chair sat in the corner where it had been ...</td>\n",
       "      <td>elle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vega</td>\n",
       "      <td>cierra</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "      <td>science</td>\n",
       "      <td>434648</td>\n",
       "      <td>434648.txt</td>\n",
       "      <td>The computer wouldn't start. She banged on the...</td>\n",
       "      <td>people</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cantrell</td>\n",
       "      <td>alden</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>science</td>\n",
       "      <td>532970</td>\n",
       "      <td>532970.txt</td>\n",
       "      <td>Do you really listen when you are talking with...</td>\n",
       "      <td>ebony</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  last_name first_name  age  years_of_journalism college major  article_id  \\\n",
       "0      west    enrique   56                   12    humanities      551293   \n",
       "1     braun     damien   43                   13    humanities      373587   \n",
       "2    osborn      ellie   22                    2   engineering      597061   \n",
       "3      vega     cierra   67                   34       science      434648   \n",
       "4  cantrell      alden   53                   23       science      532970   \n",
       "\n",
       "     filename                                               text  labels  \\\n",
       "0  551293.txt  The rain and wind abruptly stopped, but the sk...  people   \n",
       "1  373587.txt  She patiently waited for his number to be call...  people   \n",
       "2  597061.txt  The chair sat in the corner where it had been ...    elle   \n",
       "3  434648.txt  The computer wouldn't start. She banged on the...  people   \n",
       "4  532970.txt  Do you really listen when you are talking with...   ebony   \n",
       "\n",
       "   split  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create training labels\n",
    "labels = ['elle']*5 + ['people']*10 + ['ebony']*5\n",
    "full_df['labels'] = pd.Series(labels).sample(frac=1, random_state=2345).reset_index(drop=True)\n",
    "\n",
    "#create split labels\n",
    "splits = [0]*15 + [1]*5\n",
    "full_df['split'] = pd.Series(splits).sample(frac=1, random_state=2323).reset_index(drop=True)\n",
    "\n",
    "#view\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acdc1af-37c3-4e95-bfb9-b302bd4cde3d",
   "metadata": {},
   "source": [
    "## Convert into Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cac55-e0a6-4007-ad19-714f17391ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(full_df.query('split==0'))\n",
    "valid_ds = Dataset.from_pandas(full_df.query('split==1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558ecf4-e35b-4afa-a1aa-ca16e86ab432",
   "metadata": {},
   "source": [
    "# 4. Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a7940-ae31-4efe-9398-93da6b2b0aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-cased'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer.name_or_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71deff6d-3c8a-4bfc-9b5c-c532ef5cdfd7",
   "metadata": {},
   "source": [
    "# 5. Tokenize Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d994af-196d-4dba-8c1b-95a75d8fa14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85496e2cfd8f49b1b70039b2cebc3862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326f0492b292443b8dce0281a010a2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_train = train_ds.map(tokenize_function, batched=True)\n",
    "tokenized_valid = valid_ds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08845526-78fb-4096-bb4b-1ca13c7eda12",
   "metadata": {},
   "source": [
    "# 6. Split Data\n",
    "Already done above!  Whoo!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da664a0-b63c-450a-ae74-bab101d55ea1",
   "metadata": {},
   "source": [
    "# 7. Create Model for Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606be9d-e38c-48dd-9a8b-73be81ab5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=len(full_df.query('split==0')['labels'].unique()))\n",
    "model.name_or_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf580c86-c17e-47d2-b63a-39df13c0d373",
   "metadata": {},
   "source": [
    "# 8. Setup arguments for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa52fcb-33c9-4a6f-a165-719e19b19f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir=test_trainer, overwrite_output_dir=False, do_train=False, do_eval=False, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs\\May25_18-46-17_PROVL-CX0L7Y2, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=test_trainer, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, _n_gpu=1, mp_parameters=)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test_trainer\")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286fc86-ecde-470c-a605-2e467c1b92e8",
   "metadata": {},
   "source": [
    "# 9. Train model (no output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa3713-39b5-4b88-8d41-e2fe41a72ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer = Trainer(model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8598b19-507a-4594-a772-cba9e2bb6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc468b0-0f24-42aa-8642-3e8207394f42",
   "metadata": {},
   "source": [
    "# 10. Train model using evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53139608-67f6-417b-9d9c-9218c2f228f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b28b3-3eaa-438c-92b4-8931485b273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
