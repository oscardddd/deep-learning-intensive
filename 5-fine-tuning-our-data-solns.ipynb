{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4849f3-51e1-4299-9f55-9c70c1f1c431",
   "metadata": {},
   "source": [
    "# Fine Tuning Models - Using Custom Data\n",
    "> Fine-tuning using your own data\n",
    "\n",
    "In this notebook, we'll use:https://huggingface.co/transformers/custom_datasets.html as a guide for our work.  The notebook headers mirror the ones of notebook 3.  However, in this notebook, we'll use our own custom data available through our `workshop-files` subdirectory.  Some code has already been provided from Notebook 2.  Other code, we will write together.  See the solutions notebook if you fall behind!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e35b6-6e7f-4a59-8ed5-9bb9ebbb8e43",
   "metadata": {},
   "source": [
    "# 0. Preliminaries\n",
    "You can use the following code to mount your drive and cd into the relevant directory.  Uncomment the git clone command if you don't have the `deep-learning-intensive` repo already cloned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ae6a5-1b4f-43de-b950-89ddf24269f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29480a8e-de29-4a9c-b700-4ed4b48c5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive\n",
    "#!git clone https://github.com/vanderbilt-data-science/deep-learning-intensive.git\n",
    "%cd deep-learning-intensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abbc1b7-f4b4-4cdd-93ed-ce92742fe4c6",
   "metadata": {},
   "source": [
    "# 1.  Installing Required Packages\n",
    "Note that this is mostly required if you're on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067752c-e281-4ffe-9140-828d158751a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers\n",
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4f46c-e1c0-4abc-9498-a45211bcf9a6",
   "metadata": {},
   "source": [
    "# 2. Importing Packages for Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa3949-c286-4a82-af4f-c5f7594a6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a371ec-98f5-4be7-b085-a2eed2f9c3d3",
   "metadata": {},
   "source": [
    "# 3. Load Data\n",
    "## Read in data and convert to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b6693-573c-4515-b3bc-0a70c43945c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_journalism</th>\n",
       "      <th>college major</th>\n",
       "      <th>article_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>west</td>\n",
       "      <td>enrique</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>humanities</td>\n",
       "      <td>551293</td>\n",
       "      <td>551293.txt</td>\n",
       "      <td>The rain and wind abruptly stopped, but the sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>braun</td>\n",
       "      <td>damien</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>humanities</td>\n",
       "      <td>373587</td>\n",
       "      <td>373587.txt</td>\n",
       "      <td>She patiently waited for his number to be call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osborn</td>\n",
       "      <td>ellie</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>engineering</td>\n",
       "      <td>597061</td>\n",
       "      <td>597061.txt</td>\n",
       "      <td>The chair sat in the corner where it had been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vega</td>\n",
       "      <td>cierra</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "      <td>science</td>\n",
       "      <td>434648</td>\n",
       "      <td>434648.txt</td>\n",
       "      <td>The computer wouldn't start. She banged on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cantrell</td>\n",
       "      <td>alden</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>science</td>\n",
       "      <td>532970</td>\n",
       "      <td>532970.txt</td>\n",
       "      <td>Do you really listen when you are talking with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  last_name first_name  age  years_of_journalism college major  article_id  \\\n",
       "0      west    enrique   56                   12    humanities      551293   \n",
       "1     braun     damien   43                   13    humanities      373587   \n",
       "2    osborn      ellie   22                    2   engineering      597061   \n",
       "3      vega     cierra   67                   34       science      434648   \n",
       "4  cantrell      alden   53                   23       science      532970   \n",
       "\n",
       "     filename                                               text  \n",
       "0  551293.txt  The rain and wind abruptly stopped, but the sk...  \n",
       "1  373587.txt  She patiently waited for his number to be call...  \n",
       "2  597061.txt  The chair sat in the corner where it had been ...  \n",
       "3  434648.txt  The computer wouldn't start. She banged on the...  \n",
       "4  532970.txt  Do you really listen when you are talking with...  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get filenames list\n",
    "filenames = glob.glob('workshop-files/*.txt')\n",
    "\n",
    "#read file contents\n",
    "file_contents = []\n",
    "for file in filenames:\n",
    "    with open(file, 'r') as f:\n",
    "        file_contents.append(f.read())\n",
    "\n",
    "#convert to df\n",
    "tinfo_df = pd.DataFrame({'filename':[fname.split('/')[-1] for fname in filenames], 'text':file_contents})\n",
    "tinfo_df['article_id'] = tinfo_df['filename'].apply(lambda x: int(x.split('.')[0]))\n",
    "\n",
    "#read author csv\n",
    "author_df = pd.read_csv('workshop-files/author_data.csv')\n",
    "\n",
    "#join\n",
    "full_df = pd.merge(author_df, tinfo_df, on='article_id')\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a908fd-e893-48cd-9753-d6d3f4b8d6c5",
   "metadata": {},
   "source": [
    "## Add training labels and split column\n",
    "Note that our data currently doesn't have any training labels, so I'll make some up here add concatenate them to the dataframe.  I'll also add a split column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651cce0-60eb-44b8-9ef0-835c27c09196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_journalism</th>\n",
       "      <th>college major</th>\n",
       "      <th>article_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>west</td>\n",
       "      <td>enrique</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>humanities</td>\n",
       "      <td>551293</td>\n",
       "      <td>551293.txt</td>\n",
       "      <td>The rain and wind abruptly stopped, but the sk...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>braun</td>\n",
       "      <td>damien</td>\n",
       "      <td>43</td>\n",
       "      <td>13</td>\n",
       "      <td>humanities</td>\n",
       "      <td>373587</td>\n",
       "      <td>373587.txt</td>\n",
       "      <td>She patiently waited for his number to be call...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osborn</td>\n",
       "      <td>ellie</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>engineering</td>\n",
       "      <td>597061</td>\n",
       "      <td>597061.txt</td>\n",
       "      <td>The chair sat in the corner where it had been ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vega</td>\n",
       "      <td>cierra</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "      <td>science</td>\n",
       "      <td>434648</td>\n",
       "      <td>434648.txt</td>\n",
       "      <td>The computer wouldn't start. She banged on the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cantrell</td>\n",
       "      <td>alden</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>science</td>\n",
       "      <td>532970</td>\n",
       "      <td>532970.txt</td>\n",
       "      <td>Do you really listen when you are talking with...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  last_name first_name  age  years_of_journalism college major  article_id  \\\n",
       "0      west    enrique   56                   12    humanities      551293   \n",
       "1     braun     damien   43                   13    humanities      373587   \n",
       "2    osborn      ellie   22                    2   engineering      597061   \n",
       "3      vega     cierra   67                   34       science      434648   \n",
       "4  cantrell      alden   53                   23       science      532970   \n",
       "\n",
       "     filename                                               text  labels  \\\n",
       "0  551293.txt  The rain and wind abruptly stopped, but the sk...       0   \n",
       "1  373587.txt  She patiently waited for his number to be call...       1   \n",
       "2  597061.txt  The chair sat in the corner where it had been ...       0   \n",
       "3  434648.txt  The computer wouldn't start. She banged on the...       0   \n",
       "4  532970.txt  Do you really listen when you are talking with...       1   \n",
       "\n",
       "   split  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create training labels\n",
    "label_dict = {0:'elle', 1:'people'}\n",
    "labels = [0]*10 + [1]*10\n",
    "full_df['labels'] = pd.Series(labels).sample(frac=1, random_state=2345).reset_index(drop=True)\n",
    "\n",
    "#create split labels\n",
    "splits = [0]*15 + [1]*5\n",
    "full_df['split'] = pd.Series(splits).sample(frac=1, random_state=2323).reset_index(drop=True)\n",
    "\n",
    "#view\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558ecf4-e35b-4afa-a1aa-ca16e86ab432",
   "metadata": {},
   "source": [
    "# 4. Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a7940-ae31-4efe-9398-93da6b2b0aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-cased'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer.name_or_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71deff6d-3c8a-4bfc-9b5c-c532ef5cdfd7",
   "metadata": {},
   "source": [
    "# 5. Tokenize Inputs and Convert to PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d994af-196d-4dba-8c1b-95a75d8fa14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tokenized representations\n",
    "train_encodings = tokenizer(full_df.query('split==0')['text'].tolist(), truncation=True, padding='longest')\n",
    "val_encodings = tokenizer(full_df.query('split==1')['text'].tolist(), truncation=True, padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc59e5-52b9-4449-8cda-bd94e88e980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers for class size and class names\n",
    "no_classes = len(full_df.query('split==0')['labels'].unique())\n",
    "train_classes = [label_dict[class_ind] for class_ind in range(no_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061e38a-4e26-4294-8a3f-99f3a51de49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create custom Datasets Class\n",
    "class ArticlesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "#Create datasets from encodings\n",
    "train_dataset = ArticlesDataset(train_encodings, full_df.query('split==0')['labels'].tolist())\n",
    "val_dataset = ArticlesDataset(val_encodings, full_df.query('split==1')['labels'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08845526-78fb-4096-bb4b-1ca13c7eda12",
   "metadata": {},
   "source": [
    "# 6. Split Data\n",
    "Already done above!  Whoo!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da664a0-b63c-450a-ae74-bab101d55ea1",
   "metadata": {},
   "source": [
    "# 7. Create Model for Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606be9d-e38c-48dd-9a8b-73be81ab5d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bert-base-cased'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=no_classes, id2label=label_dict)\n",
    "model.name_or_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf580c86-c17e-47d2-b63a-39df13c0d373",
   "metadata": {},
   "source": [
    "# 8. Setup arguments for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa52fcb-33c9-4a6f-a165-719e19b19f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir=test_trainer, overwrite_output_dir=False, do_train=False, do_eval=False, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs\\May26_02-10-13_PROVL-CX0L7Y2, logging_strategy=IntervalStrategy.EPOCH, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=test_trainer, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=[], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, _n_gpu=1, mp_parameters=)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"test_trainer\",\n",
    "                                 logging_strategy='epoch')\n",
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286fc86-ecde-470c-a605-2e467c1b92e8",
   "metadata": {},
   "source": [
    "# 9. Train model (without computing metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa3713-39b5-4b88-8d41-e2fe41a72ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer = Trainer(model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8598b19-507a-4594-a772-cba9e2bb6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc468b0-0f24-42aa-8642-3e8207394f42",
   "metadata": {},
   "source": [
    "# 10. Train model using evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53139608-67f6-417b-9d9c-9218c2f228f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b28b3-3eaa-438c-92b4-8931485b273b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.779600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.642300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=0.7059771219889323, metrics={'train_runtime': 3.5836, 'train_samples_per_second': 1.674, 'total_flos': 3830988719700.0, 'epoch': 3.0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba1189-3e5f-42ae-bfae-e79f85a439f5",
   "metadata": {},
   "source": [
    "# 11. Additional Exercises with `Trainer`\n",
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bd0ec-ec3f-4f0f-b52f-70c19f6a79b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6205865144729614,\n",
       " 'eval_accuracy': 0.8,\n",
       " 'eval_runtime': 0.368,\n",
       " 'eval_samples_per_second': 40.759,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f6ec1-24fb-43f7-a52a-1cdab4861fc5",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83797f24-bcfb-405d-9f3a-01c8b26fd7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.29494038, -0.5705005 ],\n",
       "       [-0.59375405, -0.46901992],\n",
       "       [-0.2581168 , -0.4892554 ],\n",
       "       [-0.20425233, -0.61265355],\n",
       "       [-0.5602172 , -0.5579459 ],\n",
       "       [-0.2200632 , -0.5284079 ],\n",
       "       [-0.55317354, -0.5999937 ],\n",
       "       [-0.4260145 , -0.45691708],\n",
       "       [-0.36270788, -0.3824813 ],\n",
       "       [-0.42646652, -0.30376187],\n",
       "       [-0.37042508, -0.28922018],\n",
       "       [-0.1676437 , -0.5701666 ],\n",
       "       [-0.6241655 , -0.407779  ],\n",
       "       [-0.54866135, -0.4822002 ],\n",
       "       [-0.5887574 , -0.47976074]], dtype=float32), label_ids=array([0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1], dtype=int64), metrics={'test_loss': 0.6205865144729614, 'test_accuracy': 0.8, 'test_runtime': 0.3172, 'test_samples_per_second': 47.291})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad2ce4-1806-4bf3-9b68-6afa33356b82",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a777f-2b74-43b5-ab8f-b8746165d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('bert-magazine-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94abc5f1-076e-4167-9c85-26d77404797f",
   "metadata": {},
   "source": [
    "## Use as pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9238bf-3e4c-4558-99a9-72fbbf328787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'elle', 'score': 0.5684574842453003},\n",
       " {'label': 'people', 'score': 0.531143069267273},\n",
       " {'label': 'elle', 'score': 0.5575286746025085},\n",
       " {'label': 'elle', 'score': 0.6007044315338135},\n",
       " {'label': 'elle', 'score': 0.5512022972106934},\n",
       " {'label': 'people', 'score': 0.5005678534507751},\n",
       " {'label': 'elle', 'score': 0.5764812231063843},\n",
       " {'label': 'elle', 'score': 0.5117030143737793},\n",
       " {'label': 'elle', 'score': 0.5077250003814697},\n",
       " {'label': 'elle', 'score': 0.5049431920051575},\n",
       " {'label': 'people', 'score': 0.5306376218795776},\n",
       " {'label': 'people', 'score': 0.5202901363372803},\n",
       " {'label': 'elle', 'score': 0.5992936491966248},\n",
       " {'label': 'people', 'score': 0.5538864135742188},\n",
       " {'label': 'elle', 'score': 0.5338598489761353},\n",
       " {'label': 'people', 'score': 0.5166091918945312},\n",
       " {'label': 'elle', 'score': 0.5768876075744629},\n",
       " {'label': 'people', 'score': 0.5069248676300049},\n",
       " {'label': 'elle', 'score': 0.5140368342399597},\n",
       " {'label': 'people', 'score': 0.527222216129303}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_classifier = pipeline('text-classification', model='bert-magazine-classifier')\n",
    "mag_classifier(full_df['text'].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
